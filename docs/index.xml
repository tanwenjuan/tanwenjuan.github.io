<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Documentation on Wenjuan Tan</title>
    <link>http://localhost:1313/docs/</link>
    <description>Recent content in Documentation on Wenjuan Tan</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Nov 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/docs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Biography</title>
      <link>http://localhost:1313/docs/biography/</link>
      <pubDate>Mon, 24 Jan 2022 14:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/biography/</guid>
      <description></description>
    </item>
    <item>
      <title>Research</title>
      <link>http://localhost:1313/docs/research/</link>
      <pubDate>Mon, 25 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/research/</guid>
      <description>&lt;h2 id=&#34;ai-for-drug-discovery&#34;&gt;AI for Drug Discovery&lt;/h2&gt;&#xA;&lt;p&gt;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/AiProtacs.png&#34; alt=&#34;AiProtacs: a PROTAC-targeted-degradation discriminator augmented with graph contrastive learning&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;AiProtacs: a PROTAC-targeted-degradation discriminator augmented with graph contrastive learning&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;Xiang-Zhe Kong, &lt;u&gt;Wen-Juan Tan&lt;/u&gt;, Ren-Hong Sun, Li Zhang, Fang-Yuan Ren, Chao-Wei Ren, Xiao-Bao Yang, Wen-Bing Huang*, Yang Liu*&lt;/em&gt;&lt;br&gt; &lt;em&gt;Submitted to &lt;b&gt;Nature Communications&lt;/b&gt;&lt;/em&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/website_materials/blob/main/AiProtacs.pdf&#39; style=&#39;color: #007bff;&#39;&gt;Paper&lt;/a&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;I developed AiPROTACs, a deep learning model that leverages graph-based neural networks and a hybrid learning framework to predict the degradation efficacy of PROTACs (Proteolysis Targeting Chimeras).The model achieved an accuracy of 85.02% on both the PROTAC-DB2.0 dataset and external datasets.To validate the model&#39;s predictive capabilities, I applied it to identify potential androgen receptor-targeting PROTACs, which were synthesized and experimentally tested.Of the 16 synthesized candidates, 75% showed predicted degradation efficacy, with one lead candidate exhibiting promising in vitro degradation activity.The AiPROTACs model significantly streamlined the PROTAC discovery process, improving degradation efficiency and specificity, which in turn accelerates drug development timelines.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;                &lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&#xA;  &lt;div class=&#34;initial row project without-separator&#34;&gt;&#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/EPT_drug_screen.png&#34; alt=&#34;Equivariant Pretrained Transformer: AI Accelerated Drug Screening for COVID-19&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;Equivariant Pretrained Transformer: AI Accelerated Drug Screening for COVID-19&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;Rui Jiao, Xiang-Zhe Kong, Zi-Yang Yu, &lt;u&gt;Wen-Juan Tan&lt;/u&gt;, Li Zhang, Fang-Yuan Ren, Wen-Bing Huang*, Yang Liu*&lt;/em&gt;&lt;br&gt; &lt;em&gt;Submitted to &lt;b&gt;Nature Machine Intelligence&lt;/b&gt;&lt;/em&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/website_materials/blob/main/EPT.pdf&#39; style=&#39;color: #007bff;&#39;&gt;Paper&lt;/a&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;I used EPT (Equivariant Pretrained Transformer), which integrates E(3) equivariance into transformers, for AI-driven drug screening in COVID-19 research. By leveraging its enhanced representation, I applied it to small molecule and protein modeling, improving 3D structure accuracy and cross-domain learning.Experimental results showed that EPT outperformed existing methods in ligand binding affinity prediction and delivered strong performance in molecular and protein property tasks.The model showed promising results in anti-COVID drug screening.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/DHD2iff.png&#34; alt=&#34;DHD2iff: A Docking-Guided Hierarchical Dual Diffusion Model for Target-aware Drug Design&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;DHD2iff: A Docking-Guided Hierarchical Dual Diffusion Model for Target-aware Drug Design&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;&lt;u&gt;Wenjuan Tan&lt;/u&gt;, Ximing Wen, Ziyang Yu, Wenbing Huang*, Yang Liu*&lt;/em&gt;&lt;br&gt; &lt;em&gt;Submitted to &lt;b&gt;ICML 2025&lt;/b&gt;&lt;/em&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/website_materials/blob/main/DHD2iff.pdf&#39; style=&#39;color: #007bff;&#39;&gt;Paper&lt;/a&gt; &amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/DHD2iff&#39; style=&#39;color: #28a745;&#39;&gt;Code&lt;/a&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;I contributed to the development of DHD2iff, a dual diffusion model designed for generating small molecules targeting protein pockets. The model builds on diffusion-based approaches and incorporates a hierarchical graph structure and attention mechanism to refine molecular interactions, enhancing both stability and conformational accuracy. Experiments on the CrossDocked2020 dataset demonstrated that DHD2iff outperformed existing models, generating high-affinity and stable molecules.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/Unilinker.jpg&#34; alt=&#34;Unilinker: A Unified Model for Linker Design in Targeted Drug Development&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;Unilinker: A Unified Model for Linker Design in Targeted Drug Development&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;Li Zhang, &lt;em&gt;&lt;u&gt;Wenjuan Tan&lt;/u&gt;, Ziyang Yu, Wenbing Huang*, Yang Liu*&lt;/em&gt;&lt;br&gt; &lt;em&gt;&lt;b&gt;In Process&lt;/b&gt;&lt;/em&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/Unilinker&#39; style=&#39;color: #28a745;&#39;&gt;Code&lt;/a&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;In targeted drug design, the linker plays a pivotal role, often directly influencing the drug&#39;s efficacy. Targeted drugs encompass a variety of types, including polymorphs and antibody-drug conjugates, among others. To standardize the design process, we propose the Unilinker model, a unified framework for linker design applicable across different categories of targeted drugs. We have developed a Variational Autoencoder (VAE) model, incorporating diffusion within the latent space, to generate a comprehensive linker design approach. Furthermore, during the design process, we leverage a linker template library to guide the linker generation, with the infusion of template knowledge significantly enhancing the validity of the generated linkers. This is particularly beneficial in the design of complex linkers, ensuring more effective and optimized solutions.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;large-language-modelsllms&#34;&gt;Large Language Models(LLMs)&lt;/h2&gt;&#xA;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/GAProtoNet.png&#34; alt=&#34;GAProtoNet: Enhancing LLM Interpretability with Graph Attention-Based Prototypical Model&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;GAProtoNet: Enhancing LLM Interpretability with Graph Attention-Based Prototypical Model&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;Ximing Wen, &lt;u&gt;Wenjuan Tan&lt;/u&gt;, Rosina O. Weber*&lt;/em&gt;&lt;br&gt; &lt;em&gt;Accepted by &lt;b&gt;COLLING 2025&lt;/b&gt;&lt;/em&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/website_materials/blob/main/GAProtoNet.pdf&#39; style=&#39;color: #007bff;&#39;&gt;Paper&lt;/a&gt; &amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/GAProtoNet/tree/main&#39; style=&#39;color: #28a745;&#39;&gt;Code&lt;/a&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;I proposed a novel white-box multi-head graph attention prototypical network (GAProtoNet), aimed at improving the interpretability of LLMs. GAProtoNet combines prototypical learning with multi-head graph attention mechanisms to better capture deep features of text data and provide visual explanations for classification decisions. Extensive experiments on multiple public benchmark datasets, using different language models demonstrated GAProtoNet’s superiority in both classification performance and interpretability.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/RLHF.png&#34; alt=&#34;Prototype-Enhanced Reinforcement Learning for LLM Fine-Tuning with Sparse Human Feedback&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;Prototype-Enhanced Reinforcement Learning for LLM Fine-Tuning with Sparse Human Feedback&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;Ximing Wen, &lt;u&gt;Wenjuan Tan&lt;/u&gt;, Rosina O. Weber*&lt;/em&gt;&lt;br&gt; &lt;em&gt;&lt;b&gt;In Process&lt;/b&gt;&lt;/em&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;I proposed a novel white-box multi-head graph attention prototypical network (GAProtoNet), aimed at improving the interpretability of LLMs. GAProtoNet combines prototypical learning with multi-head graph attention mechanisms to better capture deep features of text data and provide visual explanations for classification decisions. Extensive experiments on multiple public benchmark datasets, using different language models demonstrated GAProtoNet’s superiority in both classification performance and interpretability.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/RLHF.png&#34; alt=&#34;Prototype-Enhanced Reinforcement Learning for LLM Fine-Tuning with Sparse Human Feedback&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;Prototype-Enhanced Reinforcement Learning for LLM Fine-Tuning with Sparse Human Feedback&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;Ximing Wen, &lt;u&gt;Wenjuan Tan&lt;/u&gt;, Rosina O. Weber*&lt;/em&gt;&lt;br&gt; &lt;em&gt;&lt;b&gt;In Process &lt;/b&gt;&lt;/em&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;The answers generated by LLMs are sometimes useful, but at other times they are not. To train a better model that provides useful answers to users, fine-tuning based on user feedback is necessary. However, due to the limited amount of labeled data, fine-tuning LLMs using Reinforcement Learning from Human Feedback (RLHF) sometimes fails to achieve effective results. We propose a prototype reward model that leverages the prototype&#39;s suitability for few-shot learning, and constructs a reward model based on human feedback. The reward score generated from the output is then used to train the reinforcement learning model.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;ai--healthcare&#34;&gt;AI + Healthcare&lt;/h2&gt;&#xA;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/TIS.png&#34; alt=&#34;Diaphragm motion and shape as a function of the scoliotic spinal curve in thoracic insufficiency syndrome (TIS)&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;Diaphragm motion and shape as a function of the scoliotic spinal curve in thoracic insufficiency syndrome (TIS)&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;&lt;u&gt;Wenjuan Tan&lt;/u&gt;, Jayaram K Udupa*, Yubing Tong, Caiyun Wu, Mahdie Hosseini, Mostafa Al-Noury, Shiva Shaghaghi, Joseph M McDonough, Samantha Gogel, David M Biko, Oscar H Mayer, Jason B Anari, Drew A Torigian, Patrick J Cahill&lt;/em&gt;&lt;br&gt; &lt;em&gt;Published in &lt;b&gt;SPIE. Medical Imaging 2024: Clinical and Biomedical Imaging&lt;/b&gt;&lt;/em&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/website_materials/blob/main/SPIE.pdf&#39; style=&#39;color: #007bff;&#39;&gt;Paper&lt;/a&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;I worked on a project focused on analyzing thoracic movement and respiratory patterns in patients with Thoracic Insufficiency Syndrome (TIS) using dynamic MRI sequences. I applied optical flow techniques to estimate feature point motion, extracting key information about thoracic movement, including dynamic trajectory and speed during different respiratory phases. Additionally, I segmented the diaphragm and other respiratory muscles to analyze their movement, speed, and shape trajectories, creating 3D rendered animations to visualize their motion throughout the breathing process. Through statistical analysis, I identified unique respiratory characteristics among different TIS patient types, which contributed valuable insights for clinical diagnosis and treatment.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;robotics&#34;&gt;Robotics&lt;/h2&gt;&#xA;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;img src=&#34;http://localhost:1313/img/multi-robotics.png&#34; alt=&#34;Decentralized Formation Control for Multi-Robot Systems in Dynamic Environments&#34; class=&#34;img-fluid project-img&#34;&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;Decentralized Formation Control for Multi-Robot Systems in Dynamic Environments&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;&lt;u&gt;Wenjuan Tan (Group Leader)&lt;/u&gt;, Zeyang Li, Zikang Shi, Ruibin Liang&lt;/em&gt;&lt;br&gt; &lt;em&gt;Course Project: &lt;b&gt;ME452 Multi-robot system and control &lt;/b&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; Rating:A+&lt;/em&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/website_materials/blob/main/Multi-robotics.pdf&#39; style=&#39;color: #007bff;&#39;&gt;Paper&lt;/a&gt; &amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/multirobots&#39; style=&#39;color: #28a745;&#39;&gt;Code&lt;/a&gt; &amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/website_materials/blob/main/Multi-robotics.mp4&#39; style=&#39;color: #dc3545;&#39;&gt;Video&lt;/a&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;I developed a distributed control system for mobile robot formation in multi-robot collaborative environments. The project addressed key challenges such as obstacle avoidance, dynamic formation selection, and formation tracking. I proposed a decentralized obstacle avoidance strategy that allowed robots to autonomously adjust their formation based on local information. Additionally, I introduced a dynamic formation selection algorithm to estimate global errors from local ones, enabling robots to reconfigure formations during obstacle avoidance while maintaining coordination. I also designed a consensus-based distributed control law to ensure stable tracking of time-varying formations. Through simulations and real-world experiments, we validated the algorithms’ robustness, scalability, and adaptability in dynamic environments. This work demonstrated the potential of decentralized control to enhance the performance and flexibility of mobile robot systems in complex real-world scenarios.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&#xA;&lt;hr&gt;&#xA;&#xA;  &lt;div class=&#34;initial row project with-separator&#34;&gt;&#xA;    &lt;hr&gt; &#xA;    &lt;div class=&#34;col-md-4 left-section&#34;&gt;&#xA;      &lt;video id=&#34;myVideo&#34; controls class=&#34;img-fluid project-video&#34;&gt;&#xA;        &lt;source src=&#34;http://localhost:1313/img/self_driving.mp4&#34; type=&#34;video/mp4&#34;&gt;&#xA;        您的浏览器不支持视频播放。&#xA;      &lt;/video&gt;&#xA;    &lt;/div&gt;&#xA;    &lt;div class=&#34;col-md-8 right-section&#34;&gt;&#xA;      &lt;h3&gt;Multi-Agent Trajectory Planning and Decision Algorithms for Intelligent Connected Vehicles in Smart Cities&lt;/h3&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;&lt;em&gt;&lt;u&gt;Wenjuan Tan (Bachelor&#39;s Thesis)&lt;/u&gt;&lt;/em&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;a href=&#39;https://github.com/tanwenjuan/website_materials/blob/main/self_driving.mp4&#39; style=&#39;color: #dc3545;&#39;&gt;Video&lt;/a&gt;&lt;/p&gt;&#xA;      &lt;p class=&#34;no-margin&#34;&gt;I developed a distributed control system for mobile robot formation in multi-robot collaborative environments. The project addressed key challenges such as obstacle avoidance, dynamic formation selection, and formation tracking. I proposed a decentralized obstacle avoidance strategy that allowed robots to autonomously adjust their formation based on local information. Additionally, I introduced a dynamic formation selection algorithm to estimate global errors from local ones, enabling robots to reconfigure formations during obstacle avoidance while maintaining coordination. I also designed a consensus-based distributed control law to ensure stable tracking of time-varying formations. Through simulations and real-world experiments, we validated the algorithms’ robustness, scalability, and adaptability in dynamic environments. This work demonstrated the potential of decentralized control to enhance the performance and flexibility of mobile robot systems in complex real-world scenarios.&lt;/p&gt;&#xA;    &lt;/div&gt;&#xA;  &lt;/div&gt;&#xA;&#xA;&#xA;&lt;script&gt;&#xA;  var video = document.getElementById(&#39;myVideo&#39;);&#xA;  &#xA;  &#xA;  video.addEventListener(&#39;ended&#39;, function() {&#xA;    video.currentTime = 0;  &#xA;    video.play();           &#xA;  });&#xA;&#xA;  &#xA;  video.play();&#xA;&lt;/script&gt;&#xA;&lt;hr&gt;</description>
    </item>
    <item>
      <title>Publications</title>
      <link>http://localhost:1313/docs/publications/</link>
      <pubDate>Mon, 24 Jan 2022 14:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/publications/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;AiProtacs: A PROTAC-targeted-degradation discriminator augmented with graph contrastive learning&lt;/strong&gt;&lt;br&gt;&#xA;Xiang-Zhe Kong, &lt;!-- raw HTML omitted --&gt;Wen-Juan Tan&lt;!-- raw HTML omitted --&gt;, Ren-Hong Sun, Li Zhang, Fang-Yuan Ren, Chao-Wei Ren, Xiao-Bao Yang, Wen-Bing Huang*, Yang Liu*&#xA;Submitted to &lt;em&gt;Nature Communications&lt;/em&gt;     &lt;a href=&#34;https://github.com/tanwenjuan/website_materials/blob/main/AiProtacs.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;DHD2iff: A Docking-Guided Hierarchical Dual Diffusion Model for Target-aware Drug Design&lt;/strong&gt;&lt;br&gt;&#xA;Wenjuan Tan, Ximing Wen, Ziyang Yu, Wenbing Huang*, Yang Liu*&lt;br&gt;&#xA;Submitted to &lt;em&gt;ICML 2025&lt;/em&gt;     &lt;a href=&#34;https://github.com/tanwenjuan/website_materials/blob/main/DHD2iff.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;GAProtoNet: A Multi-head Graph Attention-based Prototypical Network for Interpretable Text Classification&lt;/strong&gt;&lt;br&gt;&#xA;Ximing Wen, Wenjuan Tan, Rosina O. Weber*&lt;br&gt;&#xA;Accepted by &lt;em&gt;COLLING 2025&lt;/em&gt;     &lt;a href=&#34;https://github.com/tanwenjuan/website_materials/blob/main/GAProtoNet.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Equivariant Pretrained Transformer: AI Accelerated Drug Screening for COVID-19&lt;/strong&gt;&lt;br&gt;&#xA;Rui Jiao, Xiang-Zhe Kong, Zi-Yang Yu, Wen-Juan Tan, Li Zhang, Fang-Yuan Ren, Wen-Bing Huang*, Yang Liu*&lt;br&gt;&#xA;Submitted to &lt;em&gt;Nature Machine Intelligence&lt;/em&gt;     &lt;a href=&#34;https://github.com/tanwenjuan/website_materials/blob/main/EPT.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Diaphragm motion and shape as a function of the scoliotic spinal curve in thoracic insufficiency syndrome (TIS)&lt;/strong&gt;&lt;br&gt;&#xA;Wenjuan Tan, Jayaram K Udupa*, Yubing Tong, Caiyun Wu, Mahdie Hosseini, Mostafa Al-Noury, Shiva Shaghaghi, Joseph M McDonough, Samantha Gogel, David M Biko, Oscar H Mayer, Jason B Anari, Drew A Torigian, Patrick J Cahill&lt;br&gt;&#xA;Published on &lt;em&gt;SPIE. Medical Imaging 2024: Clinical and Biomedical Imaging&lt;/em&gt;     &lt;a href=&#34;https://github.com/tanwenjuan/website_materials/blob/main/SPIE.pdf&#34;&gt;pdf&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>Honors &amp; Awards</title>
      <link>http://localhost:1313/docs/honors/</link>
      <pubDate>Mon, 24 Jan 2022 14:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/honors/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Rongchang Technology Innovation Scholarship (Top 10)                                             2020&lt;/li&gt;&#xA;&lt;li&gt;Zhiyuan Honor Scholarship (Top 5%) * 4                                           2017,2018,2019,2020&lt;/li&gt;&#xA;&lt;li&gt;Fan Xuqi Scholarship (Top 15) * 2                                                                        2018,2019&lt;/li&gt;&#xA;&lt;li&gt;Excellent Scholarship of Shanghai Jiao Tong University                                            2019&lt;/li&gt;&#xA;&lt;li&gt;Outstanding Graduate of Shanghai Jiao Tong University                                           2021&lt;/li&gt;&#xA;&lt;li&gt;Comprehensive Scholarship of Tsinghua University                                                   2023&lt;/li&gt;&#xA;&lt;li&gt;First Prize in the Course Project Exhibition                                                                   2018&lt;/li&gt;&#xA;&lt;li&gt;Second Prize in the National Mathematics Competition                                            2019&lt;/li&gt;&#xA;&lt;li&gt;Second Prize in Big Data Science Training Camp                                                        2020&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>Contact</title>
      <link>http://localhost:1313/docs/contact/</link>
      <pubDate>Mon, 24 Jan 2022 14:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/contact/</guid>
      <description>&lt;p&gt;📧 Email:13555819412@163.com; &lt;a href=&#34;mailto:tanwj21@mails.tsinghua.edu&#34;&gt;tanwj21@mails.tsinghua.edu&lt;/a&gt;&lt;br&gt;&#xA;🏠 Address: Tsinghua University, 800 Shuangqing Road, Haidian District, Beijing, China&lt;br&gt;&#xA;☎️ Tel: +86 13555819412&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
